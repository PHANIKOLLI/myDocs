====================== ====================== ====================== 
                       Namespaces
====================== ====================== ======================

NameSpaces:
  kubeadm creates 3 namespaces by default:
    - kube-system
    - default
    - kube-public
  
# namespaces
#To see list of Namespaces:
  kubectl get namespaces
  
# To create a namespace (say dev) 
 kubectl create namespace dev
 
# To create namespace usign YML file:
kubectl create -f namespace-dev.yml #check the yaml file below

-------namespace-dev.yml-------------------------
  --- 
  #namespace-dev.yml
  apiVersion: v1
  kind: Namespace
  metadata:
    name: dev
-------------------------------    

================Namespace-quotas==============================
 quota limits: Set resource limits to namespace
 
 # To create namespace usign YML file:
  --- 
  #namespace-dev-with-quota-limits.yml
  apiVersion: v1
  kind: Namespace
  metadata:
    name: dev
  spec:
    hard:
      pods: "10"
      requests.cpu: "4"
      requests.memory: 5Gi
      limits.cpu: "10"
      limits.memory: "10Gi"
 ==============================================================
====================== ====================== ====================== 
                       BASIC POD CREATION
====================== ====================== ====================== 
#To set the default Namespace (say dev)
  kubectl config set-context $(kubectl config current-context)  --namespace=dev
# YAML IN KUBERENETES BASIC
# EVERY YAML FILE SHOULD HAVE FOLLOWING
 ---
 apiVersion:
 kind:
 metadata:
 
 spec:

=========================================================
--- pod-definition.yml------and pod creation-----------------------
 apiVersion: v1
 kind: Pod 
 #here kind and api version can be 
                  #Pod  and apiVersion is v1
                  #Service and apiVersion is v1
                  #ReplicaSet and apiVersion is apps/v1
                  #Deployment and apiVersion is apps/v1
 metadata: 
    # this is the name assigned to pod ; 
    # if replicas are created additional hashcode will be added to same name
   name: myapp-pod
   #if we don't provide namespace tag here ,  then by default pods gets created in 'default' namespace
   #namespace: dev 
   labels:
     app: myapp
     type: front-end
    
 spec:
   containers:
     - name: nginx-controller
       image: nginx
       ports:
        - containerPort:80
   nodeSelector: #to schedule pods on particular node we use node selector with labels
     availableZone: 1a
     
------------commands to create pods--------------------------
#By default pods gets created in default namespace
#To create pod using above file
 kubectl create -f pod-definition.yml
#note: here -f is used to provide file as input
#or
 kubectl run myapp-pod --image=nginx --generator=run-pod/v1

#To create pod in a specific namespace (say dev)
 kubectl create -f pod-definition.yml --namespace=dev

#To see list of pods with high level information
 kubectl get pods

#To see list of pods in a specific namespace (say dev)
 kubectl get pods --namespace=dev
 
#To see list of pods with detailed information
 kubectl get pods -o wide

#To see list of pods with sort order 
 kubectl get pods -o wide --sort-by="{.spec.nodename}"

#To see list of pods with labels 
 kubectl get pods -o wide --show-labels
 
#To assign labels to nodes
 kubectl label nodes <node-name> tagname=tagvalue
 #ex: kubectl label nodes ip-123.23.123.12 availabiltyZone=1a
 
#To remove the label assignd to pod
 kubectl label pods <pod-name> <tagname> -
 #ex: to remove the tag availabiltyZone=1a then
 # kubectl label pods myapp-pod availabiltyZone -
 
#To see detailed information of pods like labels, containers, created time, events etc.
 kubectl describe pods myapp-pod

#To remove the pod by name
 kubectl delete pods <pod-name>
 
#To remove all the pods 
 kubectl delete pods --all

# Delete pods and services with label name=myLabel.
 kubectl delete pods,services -l name=myLabel
 #ex: kubectl delete pods,services -l env=dev


#Example using hostPath volumes
#If you create a node pool with three local SSDs, the host OS mounts the disks at 
#/mnt/disks/ssd0, /mnt/disks/ssd1 and /mnt/disks/ssd2. 
#Your Kubernetes containers access the disks using the hostPath parameter 
#in defined in your object's configuration file.

#This example Pod configuration file references a local SSD: /mnt/disks/ssd0:
----------------------------pod-def.yml---- with hosted volumes-----------
 apiVersion: v1
 kind: Pod
 metadata:
   name: "test-ssd"
 spec:
   containers:
   - name: "shell"
     image: "ubuntu:14.04"
     command: ["/bin/sh", "-c"]
     args: ["echo 'hello world' > /test-ssd/test.txt && sleep 1 && cat /test-ssd/test.txt"]
     volumeMounts:
     - mountPath: "/test-ssd/"
       name: "test-ssd"
   volumes:
   - name: "test-ssd"
     hostPath:
       path: "/mnt/disks/ssd0"
   nodeSelector:
     cloud.google.com/gke-local-ssd: "true"

---------------------------------------------------------------


====================== ====================== ====================== 
                       REPLICATION CONTROLLER
====================== ====================== ====================== 



---------------rc-definition.yml----creating replicas and replication conttrollers-----------
#note: the appVersion should be v1 for ReplicationController
 apiVersion: v1
 kind: ReplicationController
 metadata: 
   name: webserver-rc
   labels:
     app: webserver
     type: front-end
 spec:
   template:  
     metadata: 
       name: webserver-pod
       labels:
         app: webserver
         type: front-end    
     spec:
       container:
         - name: nginx-controller
           image: nginx  
   replicas: 3
   selector:
     env: dev
--------commands to create replication controller------------------------------------

#To create replication COntroller using above file.
 kubectl create -f rc-definition.yml

#To update the replication controller make changes in it and then apply using below command
 kubectl apply -f rc-definition.yml

#To see created replication controllers
 kubectl get replicationcontroller
#or
 kubectl get rc
#note: we can see desired-current-ready status

#To see detailed info replication controller like status events etc..
 kubectl describe rc


#To see no of pods created after running replicaiton controller
 kubectl get pods -o wide
#NOte: we can see three pods if we used above to file to create replicas

#To remove the replicationcontroller  and also pods underlying
 kubectl delete replicationcontroller webserver-rc
 
----------------------------------------------------- 

====================== ====================== ====================== 
                        REPLICA SET
====================== ====================== ====================== 


---------------ReplicaSet-definition.yml---------------
#note: the appVersion should be apps/v1 for ReplicationController
#if apiVersion is v1 , we can get error unable to recognize
 apiVersion: apps/v1
 kind: ReplicaSet
 metadata: 
   name: webserver-replicaset
   labels:
     app: webserver
     type: front-end
    
 spec:
   template:  
     metadata: 
       name: webserver-pod
       labels:
         app: webserver
         type: front-end    
     spec:
       container:
         - name: nginx-controller
           image: nginx  
   replicas: 3
   selector: #for repicaset selector is used as additonal feild
     matchLabels:
       type: front-end
----------------commands to create replica sets----------------------------

#To create replicaset using above file.
 kubectl create -f replicaset-definition.yml
#To edit the replicaSet(say rs name: webserver-replicaset)
 kubectl edit rs <replicaset-name>
 #ex: kubectl edit rs webserver-replicaset

#To export replicaset to yaml file
 kubectl get rs webserver-replicaset -o yaml > rs.yml
#-----------------------------------------------
#To increase the no. of replicas to 6 
#change the replicas to 6 in the above file
#then run the below command
 kubectl replace -f replicaset-definition.yml

#or  we can do using tags for above file
 kubectl scale --replicas=6 -f replicaset-definition.yml

#or  we can do using type and name format
 kubectl scale --replicas=6 replicaset myapp-replicaset
#-----------------------------------------------------

#To see created replicaset
 kubectl get replicaset
#note: we can see desired-current-ready status

#To see no of pods created after running replicaiton controller
 kubectl get pods -o wide
#NOte: we can see three pods if we used above to file to create replicas

#To remove the replicaset and also pods underlying
 kubectl delete replicaset webserver-replicaset

-----------------------------------------------------------------

====================== ====================== ====================== 
                             SERVICES
====================== ====================== ====================== 

---------------------Expose-service-nginx.yml------external-load-balancer-----------------------------
 apiVersion: v1
 kind: Service
 metadata:
   creationTimestamp: "2019-12-21T08:52:57Z"
   finalizers:
   - service.kubernetes.io/load-balancer-cleanup
   labels:
     app: nginx-1
   name: nginx-1-service #service name is created with this name
   namespace: default
   resourceVersion: "15225"
   selfLink: /api/v1/namespaces/default/services/nginx-1-service
   uid: c9bacdea-513d-4cf5-9d99-3d21ed77b8e9
 spec:
   clusterIP: 10.0.1.163
   externalTrafficPolicy: Cluster
   ports:
   - nodePort: 31672
     port: 80
     protocol: TCP
     targetPort: 80
   selector:
     app: nginx-1
     env: dev
   sessionAffinity: None
   type: LoadBalancer #for load balancing
   #type: nodePort #for node port
  
 status:
  loadBalancer:
    ingress:
    - ip: 35.193.18.231
--------------------------commands to create services-------------------------------
 services are used to access the application from:
    - outside of the cluster:
         <node-ip>:<nodePort>
    - within the cluster:
         <cluster-ip>
    - load balancer:
        - provided by cloud services
 
#To create service from service-nginx.yml file
 kubectl create -f service-nginx.yml
 
#To see the created service 
 kubectl get svc
 
#To see the detialsed info of services
 kubectl describe svc <service-name> 
#ex:kubectl describe svc nginx-1-service

#TO delete service 
 kubectl delete svc <service-name>
--------------------------------------------------------------------

====================== ====================== ====================== 
                              DEPLOY
====================== ====================== ====================== 

----------------nginx-deploy.yml-----no.of replicas=1
 apiVersion: apps/v1
 kind: Deployment
 metadata:
   annotations:
     deployment.kubernetes.io/revision: "1"
   creationTimestamp: "2019-12-21T08:32:52Z"
   generation: 2
   labels:
     app: nginx-1
   name: nginx-1
   namespace: default
   resourceVersion: "11734"
   selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-1
   uid: dd0f6cf8-9a1d-4f7c-bfd7-dbb4bf8e9120
 spec:
   progressDeadlineSeconds: 600
   replicas: 1
   revisionHistoryLimit: 10
   selector:
     matchLabels:
       app: nginx-1
   strategy:
     rollingUpdate:
       maxSurge: 25%
       maxUnavailable: 25%
     type: RollingUpdate
   template:
     metadata:
       creationTimestamp: null
       labels:
         app: nginx-1
     spec:
       containers:
       - image: nginx:latest
         imagePullPolicy: Always
         name: nginx
         resources: {}
         terminationMessagePath: /dev/termination-log
         terminationMessagePolicy: File
       dnsPolicy: ClusterFirst
       restartPolicy: Always
       schedulerName: default-scheduler
       securityContext: {}
       terminationGracePeriodSeconds: 30
 status:
   availableReplicas: 1
   conditions:
   - lastTransitionTime: "2019-12-21T08:32:54Z"
     lastUpdateTime: "2019-12-21T08:32:54Z"
     message: Deployment has minimum availability.
     reason: MinimumReplicasAvailable
     status: "True"
     type: Available
   - lastTransitionTime: "2019-12-21T08:32:52Z"
     lastUpdateTime: "2019-12-21T08:32:54Z"
     message: ReplicaSet "nginx-1-74c64df7b" has successfully progressed.
     reason: NewReplicaSetAvailable
     status: "True"
     type: Progressing
   observedGeneration: 2
   readyReplicas: 1
   replicas: 1
   updatedReplicas: 1



--------------------------------------------------------------------
-------------nginx-deploy.yml-----no.of replicas=3

 apiVersion: apps/v1
 kind: Deployment
 metadata:
   annotations:
     deployment.kubernetes.io/revision: "1"
   creationTimestamp: "2019-12-21T08:32:52Z"
   generation: 3
   labels:
     app: nginx-1
   name: nginx-1
   namespace: default
   resourceVersion: "17905"
   selfLink: /apis/apps/v1/namespaces/default/deployments/nginx-1
   uid: dd0f6cf8-9a1d-4f7c-bfd7-dbb4bf8e9120
 spec:
   progressDeadlineSeconds: 600
   replicas: 3
   revisionHistoryLimit: 10
   selector:
     matchLabels:
       app: nginx-1
   strategy:
     type: RollingUpdate
  #  rollingUpdate:
   #   maxSurge: 1
   #   maxUnavailable: 0
     rollingUpdate:
       maxSurge: 25%
       maxUnavailable: 25%
   template:
     metadata:
       creationTimestamp: null
       labels:
         app: nginx-1
     spec:
       containers:
       - image: nginx:latest
         imagePullPolicy: Always
         name: nginx
         resources: {}
         terminationMessagePath: /dev/termination-log
         terminationMessagePolicy: File
       dnsPolicy: ClusterFirst
       restartPolicy: Always
       schedulerName: default-scheduler
       securityContext: {}
       terminationGracePeriodSeconds: 30
 status:
   availableReplicas: 3
   conditions:
   - lastTransitionTime: "2019-12-21T08:32:52Z"
     lastUpdateTime: "2019-12-21T08:32:54Z"
     message: ReplicaSet "nginx-1-74c64df7b" has successfully progressed.
     reason: NewReplicaSetAvailable
     status: "True"
     type: Progressing
   - lastTransitionTime: "2019-12-21T09:05:38Z"
     lastUpdateTime: "2019-12-21T09:05:38Z"
     message: Deployment has minimum availability.
     reason: MinimumReplicasAvailable
     status: "True"
     type: Available
   observedGeneration: 3
   readyReplicas: 3
   replicas: 3
   updatedReplicas: 3

----------------------KUBECTL DEPLOY COMMANDS ------------

 Deployments has the strategy of deployments:
    - recreate strategy:
        Terminate old version and release new versions. ALL happens at once
    - rolling Updates:
        release the updates in incremental fashion 
        one batch after other
        once new batch is formed one by one. old batch gets terminated one by one
    - Other strategy:
        - BLUE_GREEN:
            release new version along with old version and switching traffic    
        - Canary:
            release a new version to a subset of users(say  25% users), 
            then proceed to a full rollout(remaning %75 )
        - A/B Testing:
            Routing subset of users to a new fucntionality under specific verison 
            based on certain decisions 
        

 Reasons for deployment failures :
   - insufficinet permission
   - insufficinet quota of resources
   - Image pull error
   - Application run time misconfigurations
   - Readiness probe failures
   
# To create deployment strategy
 kubectl create -f nginx-deploy.yml
 
# To see the status of the deployment 
 kubectl get deploy <deployment-name> 
 # For deployment name -> check in nginx-deploy.yml above look for name in the metadata section
 #Ex: kubectl get deploy nginx-1

# To update the no. of replicas or version no make changes in the above yml file and use below command
 kubectl apply -f nginx-deploy.yml
 
# To update the deployment and keep a track record of every deployment 
# this is done beacuase in case of any issue with deployed version we can rollback immediately
 kubectl apply -f nginx-deploy.yml --record=true
 
# To check rolling updates deployments status
 kubectl rollout status deploy <deployment-name>
 
# To check the no of replicas sets created
 kubectl get rc <replicaset-name> -o wide

# To check the history i.e REVISION NO. and CHANGE CAUSE of roll out deployments
 kubectl rollout history deploy <deployment-name>
 
# To check the detailed history of revision
 kubectl rollout history deploy <deployment-name> --revision=1
 
#To add our own message to the CHANGE CAUSE after applying changes using below command
 kubectl apply -f nginx-deploy.yml --record=true
 #run the next command to update change cause we can do this using 'kubectl annotate'
 kubectl annotate deployment.v1.apps/<deployment-name> kubernetes.io/change-cause="add your message here"
  
# To roll back the deployment to immediate pevious version 
 kubectl rollout undo deploy <deployment-name>

# To roll back the deployment to specific version or revision (say 1) 
 kubectl rollout undo deploy <deployment-name> --to-revision=1

# TO pause the deployments
 kubectl rollout pause deploy <deployment-name>
 
# TO resume the deployments
 kubectl rollout resume deploy <deployment-name>
 
#note:
 ####Deployment revision is triggered only when the 'rollout' is triggered
 ####In the deployment revision/version history only changes made to template like
 ####changing version no. and labels etc., then only deployment revision is created 
 ####other updates like scaling the deployment don't create  deployment revision.
 
--------------------------------------------------------------------------
=======================================================================
                                                                     			APP LIFE CYCLE MANAGEMENT
=======================================================================

appConfiguration:
   - Configuring Command and Arguments on applications:
        ---
        apiVersion:
        kind:
        metadata:
        spec:
          contianers:
            - name:
               image:
               command: ["sleep2.0"]  #similar to ENTRYPOINT
               args: ["10"] #similar to CMD

   - Configuring Environment Variables:
        #Key value Pair:
         ---
          #pod-def.yaml
         apiVersion:
         kind:
         metadata:
         spec:
           contianers:
            - name:
               image:
               env:
                  - name:  APP_COLOR
                     value: pink
         #To see the list of configMaps:
           kubectl get configmaps
           
        # config Maps: from literals
            kubectl create configmap <confg-name> --from-literal=<key>=<value>
                ex:  kubectl create configmap my-config --from-literal=APP_COLOR=pink \
                																	   --from-literal=APP_MOD=prod
                																	   
               # config Maps: from file
                kubectl create configmap <confg-name> --from-file=<path-to-file>
                #ex:  kubectl create configmap my-config --from-file=app_config.properties
                 --- 
                 #app_config.properties
                 APP_COLOR=pink
                 APP_MOD=prod
                 -----------------------
                 ---
                 #pod-def.yaml
                  ---
		          apiVersion:
		          kind:
		          metadata:
		          spec:
		            contianers:
		             - name:
		                image:
		             #  env:
		             #  - name: APP_COLOR
		             #     valueFrom:
		             #       ConfigMapKeyRef:
		             #         name: app-config
		             #         key: APP_COLOR
		                      
		                envFrom:
		                 - configMapRef:
		                         name: app-config
        ---
        #Config-Maps.yml:
         
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: app-config
        data:
	         APP_COLOR=pink
	         APP_MOD=prod  
              
   - Configuring Secrets:
    
    #To see list of secrets:
      kubectl get secrets
         
    #To create Secret from literals
       kubectl create secret generic <secretName>  --from-literals=<key>=<value>
      ex: kubectl create secret generic appsecret  --from-literals=DB_HOST=mysql
      
      #To create Secret from file
       kubectl create secret generic <secretName>  --from-file=<filePath>
      ex: kubectl create secret generic appsecret  --from-file=app_secret.properties
   
    #To create from yaml file:
    #Config-secret.yml:
       ---  
        apiVersion: v1
        kind: ConfigMap
        metadata:
          name: appsecret
        data:
	         DB_HOST=mysql   
	         #DB_HOST=98sdu89suv9su===  to encrypt this 'mysql'   ->  echo -n mysql | base64
               # to decrypt this 'mysql'  ->  echo -n mysql | base64 --decode   
      -----------------------------------
       kubectl create -f Config-secret.yml
     
     #To create pod from yaml file using secrets:
       
       ---
       #pod-def.yaml
         apiVersion:
         kind: Pod
         metadata:
         spec:
           contianers:
            - name:
               image:
               #can use anyone of the three below envFrom or env or volumes
               envFrom:
                 - secretRef:
                       name: appsecret
               env:
                 - name: DB_HOST
                    	valueFrom:
                    	  secretKeyRef:
                    	     name: appsecret
                    	     key: DB_HOST
               volumes:
                 - name: app-secret-volume
                    secret: 
                      secretName: appsecret
                      #note: each attribute is created as file in the volumes 
                       # vi /opt/app-secret-volume/DB_HOST
MultiContainerPods:
   In a multi-container pod, each container is expected to run a process that stays alive as long as the POD's lifecycle.
   For example in the multi-container pod that we talked about earlier that has a web application and logging agent, 
   both the containers are expected to stay alive at all times. The process running in the log agent container is 
   expected to stay alive as long as the web application is running. If any of them fails, the POD restarts.
   
InitContainers:
 -  But at times you may want to run a process that runs to completion in a container. 
    For example a process that pulls a code or binary from a repository that will be used by the main web application. 
    That is a task that will be run only  one time when the pod is first created. 
    Or a process that waits  for an external service or database to be up before the actual application starts. 
    That's where initContainers comes in.
    
   - You can configure multiple such initContainers as well, like how we did for multi-pod containers. 
      In that case each init container is run one at a time in sequential order.If any of the initContainers fail to complete,
      Kubernetes restarts the Pod repeatedly until the Init Container succeeds.
---
 apiVersion: v1
 kind: Pod
 metadata:
   name: myapp-pod
   labels:
    app: myapp
 spec:
   containers:
    - name: myapp-container
       image: busybox:1.28
       command: ['sh', '-c', 'echo The app is running! && sleep 3600']
   initContainers:
    - name: init-myservice
       image: busybox:1.28
       command: ['sh', '-c', 'until nslookup myservice; do echo waiting for myservice; sleep 2; done;']
    - name: init-mydb
       image: busybox:1.28
       command: ['sh', '-c', 'until nslookup mydb; do echo waiting for mydb; sleep 2; done;']
----------------------------------------------------------


=======================================================================
                                                                     			Scheduling 
=======================================================================
---
ManualSheduling:

   If there is no scheduler, Then pods can't be placed on nodes.
   To schedule pods manually we need to specify 'nodeName' in the definition file.
   note: we can't specify the nodeName to the running pod. We need to delete recreate deleted pod.
  ---------------------------------------------------------------------------------------------
NodeSelector:
 ---
 apiVersion:
 kind:
 metadata:
 
 spec:
    nodeName: 
 
---------------------------------------------------------------------------------------------
  TAINTS and TOLERATIONS:
      In CLUSTER ENV:  
        No pods are deployed/scheduled on Master default taint is applied on Master;
         To check the taints on masternode (say MasterNodeName = kubemaster)
           #kubectl describe node kubemaster | grep Taint
         
     - Taints are applied to Nodes:
            - taint-effect:
                   - NoSchedule: 
                           pods will not be placed on node
                   - PreferNoSchedule:
                           pods will not be placed on node (but no garuntee)
                   - NoExecute:
                           - pods will not be placed if pods tolerance is not compatible
                           - existing pods will be evicted that doesn't meet the tolerance 
     - Tolerations are applied to Pods:
   #To apply taints to nodes:
     kubectl taint nodes <node-name> <key>=<value>:taint-effect
     #ex: kubectl taint nodes node01 app=blue:NoSchedule
 #To apply taints to pod -definition:
  ---------------------------------------------------------------------------------------------
  ---
  #pod-def-with-tolerance.yml
  apiVersion:
  kind:
  metadata:
 
  spec:
    containers:
     
    tolerations:
      - key: "app"
         operator: "Equal"
         value: "blue"
         effect: "No Schedule"
   ---------------------------------------------------------------------------------------------

NodeSelector:
   
 #To add labels to nodes
   kubectl label nodes <node-name> <label-key>=<label-value>
    #ex: kubectl label nodes node-1 size=large

 #To add nodeSelector in pod definition files:
 ---
  #pod-def-with-nodeSelector.yml
        apiVersion:
        kind:
  		metadata:
 
        spec:
          containers:
            
          nodeSelector:
   --------------------------------------------------------------------------------------------------  
NodeAffinity:
    
    Types: (# availableNOW)
      - requiredDuringSchedulingIgnoredDuringExecution
      - preferredDuringSchedulingIgnoredDuringExecution
      - requiredDuringSchedulingRequiredDuringExecution (#may come in future)

   note: - DuringScheduling -> pod is created for the first time on that node
             - DuringScheduling - > pod already running on the node   
---          
  #pod-def-with-nodeaffinity.yml
        apiVersion:
        kind:
  		metadata:
 
        spec:
          containers:
          affinity:
            nodeAffinity:
              requiredDuringSchedulingIgnoredDuringExecution:
                nodeSelectorTerms:
                  - matchExpression:
                       - key: size
                          operator: Exists
                        #operator: In
                        #operator: NotIn
                             values: 
                              - Large
-------------------------------------------------------------------------------------------------------
ResourceLimits:
  
  ByDefault : each pod can use resources upto 1 vCPU and 512 Mi of RAM 
  but these limits can be modified using below tags:  
 --------------------------------------------------------------------------------------------------------
 ---
  apiVersion:
  kind:
  metadata:
  
  spec:
    containers:
      - name: 
         image:
         ports:
           - containerPort: 8080
         resources:
           requests:
              memory: "1 Gi"
              cpu: 1
           limits:
              memory: "2 Gi"
              cpu: 2
-------------------------------------------------------------------     

DaemonSets:
 - it creates one replica of pod in each node.

StaticPods:
  - kubelet can run static pods without any cluster or master arrangement.
  - static pods can be deployed using yaml manifest files
  - yaml files should be placed in this location for scheduling -> /etc/kubernetes/manifests
  - kubelet.service  -> contains the 'pod-manifest-path' by default  
  - kubelet.service  -> other way to  we can add '--config=kubeconfig.yml' and 
     in the 'kubeconfig.yml' -> mention 'staticPodPath: /etc/kubernetes/manifests'
   
MultipleSchedulers:
  - multiple schedulers can be configured in master
  - kube-scheduler.service -> contains '--config=/etc/kubernetes/config/kube-scheduler.yml'
                                                                  '--scheduler-name=default-scheduler'
   - To create custom scheduler -> create  new service (copy content in default once)
       my-custom-.service -> change the contents  '--config=/etc/kubernetes/config/my-custom-scheduler.yml'
                                                                                     '--scheduler-name=my-custom-scheduler'  
  
--- my-custom-scheduler.yml ---

  in the yaml file change the following under 'command:'
 --leader-elect=true
 --lock-object-namespace=lock-object-namespace
 --lock-object-name=lock-object-name

  # To use the custom scheduler to schedule pods 
   -> add 'schedulerName:' under containers:
   ---
       apiVersion:
       kind:
       metadata:
       spec:
          containers:
          schedulerName:
---------------------------------------
#To see the logs of the custom scheduler:
 kubectl logs my-custom-scheduler --namespace=kube-system
 
EVENTS:
  #To see list of events in the current Namespace:
   kubectl get events
  
  #To check the running/empty ports (default port of scheduler: 10251)
     netstat -natulp | grep <portNo>
               
=======================================================================
                                                                     			Metrics Server
=======================================================================

MetricsServer:
   #To install metrics server:
   git clone https://github.com/kubernetes-incubator/metrics-server.git
   #then run 
   kubectl create -f deploy/1.8+/
   
   after installtion:
   
   #To see details of cluster metrics of nodes
    kubectl top node
    
    #To see the details of pods metrics 
   kubectl top pods
   
   #To see logs of conainers
   kubectl logs -f <podName>	<containerName>
   
   
   
   
    
--- Others
 # List all pods in ps output format.
 kubectl get pods

 # List all pods in ps output format with more information (such as node name).
 kubectl get pods -o wide

 # List all pods using labels
 kubectl get pods -l environment=production, type=front-end

 # List a single replication controller with specified NAME in ps output format.
 kubectl get replicationcontroller web

 # List deployments in JSON output format, in the "v1" version of the "apps" API group:
 kubectl get deployments.v1.apps -o json

 # List a single pod in JSON output format.
 kubectl get -o json pod web-pod-13je7

 # List a pod identified by type and name specified in "pod.yaml" in JSON output format.
 kubectl get -f pod.yaml -o json

 # List resources from a directory with kustomization.yaml - e.g. dir/kustomization.yaml.
 kubectl get -k dir/

 # Return only the phase value of the specified pod.
 kubectl get -o template pod/web-pod-13je7 --template={{.status.phase}}

 # List resource information in custom columns.
 kubectl get pod test-pod -o custom-columns=CONTAINER:.spec.containers[0].name,IMAGE:.spec.containers[0].image

 # List all replication controllers and services together in ps output format.
 kubectl get rc,services

 # List one or more resources by their type and names.
 kubectl get rc/web service/frontend pods/web-pod-13je7